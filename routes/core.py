"""
Core Routes
Created: January 21, 2026
Last Updated: January 21, 2026 - Added schedule generator intercept

Main orchestration endpoint and core API routes.
NO MORE 500+ LINE FUNCTIONS. Clean and manageable.
"""

from flask import Blueprint, request, jsonify
import time
import json
import os
from datetime import datetime
from database import get_db
from orchestration import (
    analyze_task_with_sonnet,
    handle_with_opus,
    execute_specialist_task,
    validate_with_consensus
)

core_bp = Blueprint('core', __name__)

@core_bp.route('/api/orchestrate', methods=['POST'])
def orchestrate():
    """
    Main orchestration endpoint - NOW READABLE!
    Handles task analysis, specialist routing, consensus validation.
    INCLUDES: Schedule generator intercept for instant Excel creation
    """
    
    # Parse request
    if request.is_json:
        data = request.json
        user_request = data.get('request')
        enable_consensus = data.get('enable_consensus', True)
        project_id = data.get('project_id')
    else:
        user_request = request.form.get('request')
        enable_consensus = request.form.get('enable_consensus', 'true').lower() == 'true'
        project_id = request.form.get('project_id')
    
    if not user_request:
        return jsonify({'error': 'Request text required'}), 400
    
    # ==================== SCHEDULE GENERATION INTERCEPT ====================
    # CHECK IMMEDIATELY - BEFORE ANY AI PROCESSING
    # If this is a schedule request, generate Excel directly and bypass AI
    
    from app import SCHEDULE_GENERATOR_AVAILABLE, schedule_gen
    
    if SCHEDULE_GENERATOR_AVAILABLE:
        schedule_type = schedule_gen.identify_schedule_type(user_request)
        
        if schedule_type:
            print(f"  üìÖ SCHEDULE REQUEST DETECTED: {schedule_type}")
            print(f"  ‚ö° Bypassing AI - generating Excel directly")
            
            try:
                # Generate Excel schedule directly
                schedule_bytes = schedule_gen.create_schedule(schedule_type, weeks=8)
                
                # Save to outputs directory
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"schedule_{schedule_type}_{timestamp}.xlsx"
                filepath = os.path.join('/mnt/user-data/outputs', filename)
                
                # Ensure output directory exists
                os.makedirs('/mnt/user-data/outputs', exist_ok=True)
                
                with open(filepath, 'wb') as f:
                    f.write(schedule_bytes)
                
                # Get pattern info
                pattern_info = schedule_gen.get_schedule_description(schedule_type)
                
                # Create response message
                response_message = f"""‚úÖ **SCHEDULE CREATED: {pattern_info['name']}**

üìã **Pattern:** {pattern_info['description']}
üë• **Crews:** {pattern_info['crews']}
‚è∞ **Shift Length:** {pattern_info['shift_length']} hours
üìÖ **Weeks Generated:** 8

**What's in the Excel file:**
- Week-by-week schedule layout for all crews
- Color-coded shifts (Yellow = Day, Green = Night, Gray = Off)
- D = Day shift, N = Night shift, O = Off
- Professional formatting ready to use
- Legend included

**Download your schedule below** üëá
"""
                
                print(f"  ‚úÖ Schedule created successfully: {filename}")
                
                # Return immediate response WITHOUT going through AI orchestration
                return jsonify({
                    'success': True,
                    'actual_output': response_message,
                    'document_created': True,
                    'document_url': f'/api/download/{filename}',
                    'document_type': 'xlsx',
                    'knowledge_used': False,
                    'formatting_applied': False,
                    'task_id': None,
                    'execution_time_seconds': 0.5,
                    'orchestrator': 'schedule_generator',
                    'specialist_results': []
                })
                
            except Exception as e:
                print(f"  ‚ùå Schedule generation error: {e}")
                # Fall through to normal AI processing if schedule generation fails
    
    # ==================== NORMAL AI ORCHESTRATION ====================
    # If not a schedule request, or if schedule generation failed, continue with AI
    
    # Create task in database
    db = get_db()
    cursor = db.execute(
        'INSERT INTO tasks (user_request, status) VALUES (?, ?)',
        (user_request, 'analyzing')
    )
    task_id = cursor.lastrowid
    db.commit()
    
    overall_start = time.time()
    
    try:
        # Step 1: Sonnet analyzes
        from app import knowledge_base  # Import from main app
        sonnet_analysis = analyze_task_with_sonnet(user_request, knowledge_base)
        
        # Step 2: Escalate to Opus if needed
        if sonnet_analysis.get('escalate_to_opus'):
            db.execute(
                'INSERT INTO escalations (task_id, reason, sonnet_confidence) VALUES (?, ?, ?)',
                (task_id, sonnet_analysis.get('reasoning'), sonnet_analysis.get('confidence'))
            )
            db.commit()
            
            opus_plan = handle_with_opus(user_request, sonnet_analysis, knowledge_base)
            orchestrator = "opus"
            plan = opus_plan
        else:
            orchestrator = "sonnet"
            plan = sonnet_analysis
        
        # Step 3: Execute with specialists OR orchestrator handles directly
        specialist_results = []
        specialists_needed = plan.get('specialists_needed', [])
        actual_output = None
        
        if specialists_needed and specialists_needed != ["none"]:
            for specialist in specialists_needed:
                specialist_task = f"User request: {user_request}\n\nYour role as {specialist}: Complete the task using your specialty."
                result = execute_specialist_task(specialist, specialist_task)
                specialist_results.append(result)
                
                db.execute(
                    '''INSERT INTO specialist_assignments 
                       (task_id, specialist_name, specialist_role, output, execution_time_seconds, success)
                       VALUES (?, ?, ?, ?, ?, ?)''',
                    (task_id, specialist, result.get('specialist'), 
                     result.get('output'), result.get('execution_time'), result.get('success'))
                )
                db.commit()
                
                if not actual_output:
                    actual_output = result.get('output')
        else:
            # No specialists needed - orchestrator handles it directly
            from orchestration.ai_clients import call_claude_opus, call_claude_sonnet
            if orchestrator == "opus":
                actual_output = call_claude_opus(f"Complete this request:\n\n{user_request}")
            else:
                actual_output = call_claude_sonnet(f"Complete this request:\n\n{user_request}")
            
            specialist_results.append({
                "specialist": orchestrator,
                "output": actual_output,
                "execution_time": 0,
                "success": True
            })
        
        # Step 4: Consensus validation if enabled
        consensus_result = None
        if enable_consensus and actual_output:
            consensus_result = validate_with_consensus(actual_output)
            
            db.execute(
                '''INSERT INTO consensus_validations
                   (task_id, validator_ais, agreement_score, final_decision)
                   VALUES (?, ?, ?, ?)''',
                (task_id, json.dumps(consensus_result.get('validators')),
                 consensus_result.get('agreement_score'), 
                 json.dumps(consensus_result))
            )
            db.commit()
        
        total_time = time.time() - overall_start
        
        # Update task status
        db.execute(
            '''UPDATE tasks SET status = ?, assigned_orchestrator = ?, execution_time_seconds = ? 
               WHERE id = ?''',
            ('completed', orchestrator, total_time, task_id)
        )
        db.commit()
        
        return jsonify({
            'success': True,
            'task_id': task_id,
            'orchestrator': orchestrator,
            'analysis': plan,
            'actual_output': actual_output,
            'specialist_results': specialist_results,
            'consensus': consensus_result,
            'execution_time_seconds': total_time
        })
        
    except Exception as e:
        db.execute(
            'UPDATE tasks SET status = ?, result = ? WHERE id = ?',
            ('failed', str(e), task_id)
        )
        db.commit()
        
        return jsonify({
            'success': False,
            'error': str(e),
            'task_id': task_id
        }), 500
    finally:
        db.close()

@core_bp.route('/api/tasks', methods=['GET'])
def get_tasks():
    """Get all tasks"""
    db = get_db()
    tasks = db.execute('SELECT * FROM tasks ORDER BY created_at DESC LIMIT 50').fetchall()
    db.close()
    
    return jsonify([dict(task) for task in tasks])

@core_bp.route('/api/task/<int:task_id>', methods=['GET'])
def get_task_detail(task_id):
    """Get detailed task information"""
    db = get_db()
    
    task = db.execute('SELECT * FROM tasks WHERE id = ?', (task_id,)).fetchone()
    specialists = db.execute('SELECT * FROM specialist_assignments WHERE task_id = ?', (task_id,)).fetchall()
    consensus = db.execute('SELECT * FROM consensus_validations WHERE task_id = ?', (task_id,)).fetchone()
    escalation = db.execute('SELECT * FROM escalations WHERE task_id = ?', (task_id,)).fetchone()
    
    db.close()
    
    return jsonify({
        'task': dict(task) if task else None,
        'specialists': [dict(s) for s in specialists],
        'consensus': dict(consensus) if consensus else None,
        'escalation': dict(escalation) if escalation else None
    })

@core_bp.route('/api/stats', methods=['GET'])
def get_stats():
    """Get system statistics"""
    db = get_db()
    
    total_tasks = db.execute('SELECT COUNT(*) as count FROM tasks').fetchone()['count']
    sonnet_tasks = db.execute("SELECT COUNT(*) as count FROM tasks WHERE assigned_orchestrator = 'sonnet'").fetchone()['count']
    opus_tasks = db.execute("SELECT COUNT(*) as count FROM tasks WHERE assigned_orchestrator = 'opus'").fetchone()['count']
    avg_time = db.execute('SELECT AVG(execution_time_seconds) as avg FROM tasks WHERE status = "completed"').fetchone()['avg']
    
    specialist_usage = db.execute('''
        SELECT specialist_name, COUNT(*) as count 
        FROM specialist_assignments 
        GROUP BY specialist_name
    ''').fetchall()
    
    db.close()
    
    return jsonify({
        'total_tasks': total_tasks,
        'sonnet_handled': sonnet_tasks,
        'opus_handled': opus_tasks,
        'sonnet_percentage': round(sonnet_tasks / total_tasks * 100, 1) if total_tasks > 0 else 0,
        'average_time_seconds': round(avg_time, 2) if avg_time else 0,
        'specialist_usage': [dict(s) for s in specialist_usage]
    })

# I did no harm and this file is not truncated
