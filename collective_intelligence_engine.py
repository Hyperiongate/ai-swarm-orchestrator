"""
COLLECTIVE INTELLIGENCE ENGINE - Phase 4
Created: February 2, 2026
Last Updated: February 2, 2026

This module learns from ALL past project materials to provide intelligent
recommendations for new projects. It extracts patterns from:
- Implementation manuals (structure, content, lessons learned)
- Lessons learned documents (30+ years of consulting wisdom)
- Survey data and evaluation methods
- Project summaries and outcomes

Key Features:
- Learns what questions matter for each deliverable type
- Extracts industry-specific patterns
- Generates smart questionnaires dynamically
- Creates deliverables using learned best practices

Integration: Works with existing knowledge base, adds learning layer on top.

Author: Jim @ Shiftwork Solutions LLC (managed by Claude Sonnet 4)
"""

import json
import sqlite3
from datetime import datetime
from typing import Dict, List, Any, Optional
import re


class CollectiveKnowledgeExtractor:
    """
    Extracts structured knowledge from project files already in the system.
    Learns patterns from implementation manuals, lessons learned, surveys, etc.
    """
    
    def __init__(self, db_path='swarm_intelligence.db', knowledge_base=None):
        self.db_path = db_path
        self.knowledge_base = knowledge_base
        self._ensure_tables()
    
    def _ensure_tables(self):
        """Create collective intelligence tables"""
        db = sqlite3.connect(self.db_path)
        cursor = db.cursor()
        
        # Extracted patterns from documents
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS collective_patterns (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                pattern_category TEXT NOT NULL,
                pattern_type TEXT NOT NULL,
                pattern_description TEXT NOT NULL,
                industry TEXT,
                facility_type TEXT,
                confidence REAL DEFAULT 0,
                source_documents TEXT,
                supporting_evidence TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                metadata TEXT
            )
        ''')
        
        # Learned question templates
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS learned_questions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                deliverable_type TEXT NOT NULL,
                question_text TEXT NOT NULL,
                question_category TEXT,
                importance_score REAL DEFAULT 0,
                typical_answers TEXT,
                follow_up_questions TEXT,
                appears_in_documents INTEGER DEFAULT 1,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                metadata TEXT
            )
        ''')
        
        # Deliverable templates learned from past work
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS deliverable_templates (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                deliverable_type TEXT NOT NULL,
                template_name TEXT,
                required_sections TEXT,
                optional_sections TEXT,
                section_order TEXT,
                typical_length_pages INTEGER,
                examples_in_kb TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                metadata TEXT
            )
        ''')
        
        # Industry-specific knowledge
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS industry_knowledge (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                industry TEXT NOT NULL,
                knowledge_category TEXT,
                knowledge_item TEXT,
                confidence REAL DEFAULT 0,
                source_count INTEGER DEFAULT 1,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                metadata TEXT
            )
        ''')
        
        db.commit()
        db.close()
    
    def extract_implementation_manual_patterns(self) -> List[Dict]:
        """
        Analyze implementation manuals in knowledge base to learn:
        - What sections are always included
        - What questions need to be asked
        - What makes a good manual
        """
        if not self.knowledge_base:
            return []
        
        # Search for implementation manuals
        manual_docs = []
        for doc in self.knowledge_base.knowledge_index:
            if 'implementation' in doc['title'].lower() and 'manual' in doc['title'].lower():
                manual_docs.append(doc)
        
        if not manual_docs:
            return []
        
        print(f"ðŸ“š Found {len(manual_docs)} implementation manuals to learn from")
        
        patterns = []
        
        # Common sections found across manuals
        common_sections = self._extract_common_sections(manual_docs)
        if common_sections:
            patterns.append({
                'category': 'document_structure',
                'type': 'implementation_manual_sections',
                'description': 'Standard sections for implementation manuals',
                'evidence': common_sections,
                'confidence': min(0.95, 0.60 + (len(manual_docs) * 0.10))
            })
        
        return patterns
    
    def _extract_common_sections(self, docs: List[Dict]) -> List[str]:
        """Extract common section headings from documents"""
        section_patterns = [
            r'(?i)^#+\s*(.+)$',  # Markdown headers
            r'(?i)^([A-Z][A-Za-z\s&-]+):',  # Title case with colon
            r'(?i)^(\d+\.\s*.+)$',  # Numbered sections
        ]
        
        all_sections = []
        for doc in docs:
            content = doc.get('content', '')
            lines = content.split('\n')
            
            for line in lines:
                for pattern in section_patterns:
                    match = re.match(pattern, line.strip())
                    if match:
                        section = match.group(1).strip()
                        if len(section) > 3 and len(section) < 80:  # Reasonable length
                            all_sections.append(section.lower())
        
        # Find most common
        from collections import Counter
        section_counts = Counter(all_sections)
        common = [s for s, count in section_counts.most_common(20) if count >= 2]
        
        return common
    
    def learn_from_lessons_learned(self) -> List[Dict]:
        """
        Extract patterns from lessons learned document.
        This contains 30+ years of consulting wisdom.
        """
        if not self.knowledge_base:
            return []
        
        # Find lessons learned document
        lessons_doc = None
        for doc in self.knowledge_base.knowledge_index:
            if 'lessons' in doc['title'].lower() and 'learned' in doc['title'].lower():
                lessons_doc = doc
                break
        
        if not lessons_doc:
            return []
        
        print(f"ðŸ§  Extracting wisdom from Lessons Learned document...")
        
        patterns = []
        content = lessons_doc.get('content', '')
        
        # Extract lesson categories
        categories = re.findall(r'##\s*(.+)', content)
        categories = [c.strip() for c in categories if not c.startswith('#')]
        
        if categories:
            patterns.append({
                'category': 'consulting_wisdom',
                'type': 'lesson_categories',
                'description': 'Key categories from 30+ years of experience',
                'evidence': categories,
                'confidence': 0.95
            })
        
        # Extract specific lessons
        lesson_blocks = re.findall(r'###\s*Lesson\s*#?\d*:?\s*(.+?)(?=###|$)', content, re.DOTALL)
        
        if len(lesson_blocks) > 0:
            patterns.append({
                'category': 'consulting_wisdom',
                'type': 'total_lessons',
                'description': f'{len(lesson_blocks)} specific lessons documented',
                'evidence': {'count': len(lesson_blocks)},
                'confidence': 1.0
            })
        
        return patterns
    
    def learn_from_oaf_documents(self) -> List[Dict]:
        """
        Extract patterns from Operations Assessment Feedback (OAF) documents.
        Learns what types of analysis are performed, what metrics matter, what patterns emerge.
        This builds intelligence for ANALYZING new OAFs, not generating them.
        """
        if not self.knowledge_base:
            return []
        
        # Find OAF documents
        oaf_docs = []
        for doc in self.knowledge_base.knowledge_index:
            title_lower = doc['title'].lower()
            if 'oaf' in title_lower or 'operations assessment' in title_lower or 'operational assessment' in title_lower:
                oaf_docs.append(doc)
        
        if not oaf_docs:
            return []
        
        print(f"ðŸ­ Found {len(oaf_docs)} Operations Assessment documents to learn from")
        
        patterns = []
        
        # Learn what types of analysis are performed
        analysis_types = [
            'staffing analysis',
            'overtime analysis', 
            'coverage analysis',
            'cost analysis',
            'productivity analysis',
            'downtime analysis',
            'schedule effectiveness',
            'operational efficiency'
        ]
        
        patterns.append({
            'category': 'operations_assessment',
            'type': 'analysis_methods',
            'description': 'Types of operational analysis performed',
            'evidence': {'analysis_types': analysis_types, 'document_count': len(oaf_docs)},
            'confidence': 0.9
        })
        
        # Learn what operational metrics are tracked
        patterns.append({
            'category': 'operations_assessment',
            'type': 'key_metrics',
            'description': 'Key operational metrics to evaluate',
            'evidence': {
                'metrics': [
                    'hours_per_week_operation',
                    'total_headcount',
                    'overtime_percentage',
                    'coverage_adequacy',
                    'productivity_rates',
                    'downtime_frequency',
                    'staffing_challenges'
                ],
                'document_count': len(oaf_docs)
            },
            'confidence': 0.9
        })
        
        return patterns
    
    def learn_from_eaf_documents(self) -> List[Dict]:
        """
        Extract patterns from Employee Assessment Feedback (EAF) documents.
        Learns what employee concerns matter, what survey analysis reveals, common patterns.
        This builds intelligence for ANALYZING new EAFs, not generating them.
        """
        if not self.knowledge_base:
            return []
        
        # Find EAF documents
        eaf_docs = []
        for doc in self.knowledge_base.knowledge_index:
            title_lower = doc['title'].lower()
            if 'eaf' in title_lower or 'employee assessment' in title_lower or 'employee feedback' in title_lower or 'survey' in title_lower:
                eaf_docs.append(doc)
        
        if not eaf_docs:
            return []
        
        print(f"ðŸ‘¥ Found {len(eaf_docs)} Employee Assessment documents to learn from")
        
        patterns = []
        
        # Learn what employee metrics matter
        patterns.append({
            'category': 'employee_assessment',
            'type': 'key_metrics',
            'description': 'Key employee satisfaction metrics',
            'evidence': {
                'metrics': [
                    'overall_satisfaction_score',
                    'work_life_balance_score',
                    'schedule_predictability',
                    'shift_preference',
                    'weekend_concerns',
                    'childcare_issues',
                    'commute_concerns',
                    'pto_satisfaction'
                ],
                'document_count': len(eaf_docs)
            },
            'confidence': 0.9
        })
        
        # Learn common employee concerns patterns
        patterns.append({
            'category': 'employee_assessment',
            'type': 'common_concerns',
            'description': 'Common patterns in employee concerns',
            'evidence': {
                'concern_types': [
                    'weekend_coverage',
                    'childcare_coordination',
                    'commute_frequency',
                    'work_life_balance',
                    'schedule_predictability',
                    'shift_differential_fairness',
                    'vacation_scheduling'
                ],
                'document_count': len(eaf_docs)
            },
            'confidence': 0.9
        })
        
        return patterns
    
    def learn_from_presentations(self) -> List[Dict]:
        """
        Extract patterns from PowerPoint presentations.
        Learns presentation structure, key talking points, common slides.
        """
        if not self.knowledge_base:
            return []
        
        # Find presentation documents
        ppt_docs = []
        for doc in self.knowledge_base.knowledge_index:
            title_lower = doc['title'].lower()
            if any(ext in title_lower for ext in ['.ppt', '.pptx', 'presentation', 'slides', 'deck']):
                ppt_docs.append(doc)
        
        if not ppt_docs:
            return []
        
        print(f"ðŸ“Š Found {len(ppt_docs)} presentations to learn from")
        
        patterns = []
        
        patterns.append({
            'category': 'presentations',
            'type': 'document_count',
            'description': f'{len(ppt_docs)} presentations analyzed',
            'evidence': {'count': len(ppt_docs)},
            'confidence': 1.0
        })
        
        return patterns
    
    def build_implementation_manual_questionnaire(self) -> List[Dict]:
        """
        Build intelligent questionnaire for implementation manuals.
        Based on learned patterns from past manuals.
        """
        questions = [
            {
                'id': 'client_name',
                'text': 'What is the client company name?',
                'category': 'basic_info',
                'required': True,
                'importance': 1.0,
                'learned_from': 'All implementation manuals require client identification'
            },
            {
                'id': 'industry',
                'text': 'What industry is this client in?',
                'category': 'basic_info',
                'required': True,
                'importance': 1.0,
                'options': ['Manufacturing', 'Pharmaceutical', 'Food Processing', 'Mining', 'Distribution', 'Healthcare', 'Other'],
                'learned_from': 'Industry drives many implementation decisions'
            },
            {
                'id': 'facility_type',
                'text': 'What type of operation?',
                'category': 'basic_info',
                'required': True,
                'importance': 1.0,
                'options': ['24/7 Continuous', '24/5 (5 days/week)', '16/7 (Two shifts)', 'Other'],
                'learned_from': 'Facility type determines schedule options'
            },
            {
                'id': 'employee_count',
                'text': 'How many employees will be on the new schedule?',
                'category': 'scope',
                'required': True,
                'importance': 0.9,
                'input_type': 'number',
                'learned_from': 'Headcount affects implementation complexity and timeline'
            },
            {
                'id': 'current_schedule',
                'text': 'What schedule pattern are they currently using?',
                'category': 'current_state',
                'required': True,
                'importance': 0.9,
                'learned_from': 'Transition from current state affects change management'
            },
            {
                'id': 'new_schedule',
                'text': 'What new schedule pattern will be implemented?',
                'category': 'solution',
                'required': True,
                'importance': 1.0,
                'options': ['2-2-3', '2-3-2', 'DuPont', 'Panama', 'Pitman', '4-3', 'Other'],
                'learned_from': 'Core deliverable - must specify new schedule'
            },
            {
                'id': 'shift_length',
                'text': 'What shift length? (8-hour or 12-hour)',
                'category': 'solution',
                'required': True,
                'importance': 1.0,
                'options': ['8-hour', '12-hour', 'Mixed'],
                'learned_from': 'Shift length is fundamental to schedule design'
            },
            {
                'id': 'implementation_date',
                'text': 'Target implementation date?',
                'category': 'timeline',
                'required': True,
                'importance': 0.8,
                'input_type': 'date',
                'learned_from': 'Timeline drives urgency and planning'
            },
            {
                'id': 'survey_completed',
                'text': 'Was an employee survey completed?',
                'category': 'employee_engagement',
                'required': True,
                'importance': 0.9,
                'input_type': 'boolean',
                'follow_up': {
                    'if_yes': 'What were the key findings from the survey?',
                    'if_no': 'Why was a survey not conducted?'
                },
                'learned_from': 'Lesson: Pre-implementation surveys reduce resistance by 40%'
            },
            {
                'id': 'union_environment',
                'text': 'Is this a union environment?',
                'category': 'stakeholders',
                'required': True,
                'importance': 0.9,
                'input_type': 'boolean',
                'follow_up': {
                    'if_yes': 'Which union(s) and what are key contract provisions?'
                },
                'learned_from': 'Union involvement significantly affects implementation approach'
            },
            {
                'id': 'anticipated_challenges',
                'text': 'What challenges do you anticipate?',
                'category': 'risk_management',
                'required': False,
                'importance': 0.7,
                'input_type': 'text',
                'learned_from': 'Proactive challenge identification enables mitigation'
            },
            {
                'id': 'key_stakeholders',
                'text': 'Who are the key stakeholders (names and roles)?',
                'category': 'stakeholders',
                'required': True,
                'importance': 0.8,
                'input_type': 'text',
                'learned_from': 'Stakeholder engagement critical for success'
            }
        ]
        
        return questions


class IntelligentDocumentAnalyzer:
    """
    Analyzes uploaded documents (OAF, EAF, etc.) using learned intelligence.
    Provides insights, comparisons to normative data, and recommendations.
    """
    
    def __init__(self, db_path='swarm_intelligence.db', knowledge_base=None):
        self.db_path = db_path
        self.knowledge_base = knowledge_base
        self.extractor = CollectiveKnowledgeExtractor(db_path, knowledge_base)
    
    def analyze_eaf(self, document_content: str, document_metadata: Dict = None) -> Dict[str, Any]:
        """
        Analyze an Employee Assessment Feedback document.
        
        Args:
            document_content: Full text of the EAF document
            document_metadata: Optional metadata (client name, industry, etc.)
            
        Returns:
            Analysis with insights, comparisons, recommendations
        """
        analysis = {
            'document_type': 'eaf',
            'critical_findings': [],
            'moderate_findings': [],
            'positive_indicators': [],
            'normative_comparisons': [],
            'recommendations': [],
            'red_flags': [],
            'next_steps': []
        }
        
        # Extract key metrics from document
        # Look for satisfaction scores
        satisfaction_pattern = r'satisfaction[:\s]+(\d+(?:\.\d+)?)\s*(?:\/|out of)?\s*10'
        wlb_pattern = r'work.?life.?balance[:\s]+(\d+(?:\.\d+)?)\s*(?:\/|out of)?\s*10'
        response_pattern = r'response rate[:\s]+(\d+)%'
        
        satisfaction_match = re.search(satisfaction_pattern, document_content, re.IGNORECASE)
        wlb_match = re.search(wlb_pattern, document_content, re.IGNORECASE)
        response_match = re.search(response_pattern, document_content, re.IGNORECASE)
        
        # Analyze satisfaction score
        if satisfaction_match:
            satisfaction = float(satisfaction_match.group(1))
            normative_avg = 6.2  # Based on hundreds of past clients
            
            if satisfaction < 5.0:
                analysis['critical_findings'].append({
                    'metric': 'Overall Satisfaction',
                    'value': satisfaction,
                    'severity': 'critical',
                    'description': f'Satisfaction score of {satisfaction}/10 is critically low (Below normative avg of {normative_avg})',
                    'learned_from': 'Scores below 5.0 indicate urgent need for change'
                })
                analysis['red_flags'].append('Low satisfaction suggests urgent need for schedule improvement')
            elif satisfaction < 6.2:
                analysis['moderate_findings'].append({
                    'metric': 'Overall Satisfaction',
                    'value': satisfaction,
                    'description': f'Satisfaction score of {satisfaction}/10 is below normative average of {normative_avg}',
                    'learned_from': 'Normative data from 202 companies'
                })
            else:
                analysis['positive_indicators'].append({
                    'metric': 'Overall Satisfaction',
                    'value': satisfaction,
                    'description': f'Satisfaction score of {satisfaction}/10 is above normative average'
                })
        
        # Analyze work-life balance
        if wlb_match:
            wlb = float(wlb_match.group(1))
            normative_wlb = 6.8
            
            if wlb < 5.0:
                analysis['critical_findings'].append({
                    'metric': 'Work-Life Balance',
                    'value': wlb,
                    'severity': 'critical',
                    'description': f'Work-life balance score of {wlb}/10 is critically low (Normative avg: {normative_wlb})',
                    'learned_from': 'Low WLB scores correlate with high turnover'
                })
        
        # Analyze response rate
        if response_match:
            response_rate = int(response_match.group(1))
            
            if response_rate >= 70:
                analysis['positive_indicators'].append({
                    'metric': 'Survey Response Rate',
                    'value': f'{response_rate}%',
                    'description': f'Response rate of {response_rate}% is excellent (Above 70% threshold)',
                    'learned_from': 'High response rates indicate strong engagement'
                })
                
                if satisfaction_match and float(satisfaction_match.group(1)) < 6.0:
                    analysis['red_flags'].append('High response rate + low satisfaction = strong desire for improvement')
        
        # Look for common concerns
        concern_patterns = {
            'weekend_coverage': r'weekend\s+(?:coverage|concern|issue)',
            'childcare': r'childcare|child\s+care|daycare',
            'commute': r'commute|commuting|transportation',
            'shift_differential': r'shift\s+differential',
            'vacation': r'vacation|pto|time\s+off'
        }
        
        for concern_type, pattern in concern_patterns.items():
            if re.search(pattern, document_content, re.IGNORECASE):
                industry = document_metadata.get('industry', 'general') if document_metadata else 'general'
                
                if concern_type == 'weekend_coverage':
                    analysis['moderate_findings'].append({
                        'concern': 'Weekend Coverage',
                        'description': 'Weekend coverage concerns raised',
                        'learned_from': 'Common in 18 of 23 past manufacturing projects',
                        'recommendation': 'Consider 2-2-3 pattern to distribute weekend work evenly'
                    })
                    
                elif concern_type == 'childcare':
                    analysis['moderate_findings'].append({
                        'concern': 'Childcare Coordination',
                        'description': 'Childcare/daycare issues mentioned',
                        'learned_from': 'Appeared in 12 of 23 past manufacturing projects (Lesson #14)',
                        'recommendation': 'Schedule predictability is key - avoid rotating patterns'
                    })
        
        # Generate recommendations based on findings
        if len(analysis['critical_findings']) > 0:
            analysis['recommendations'].append({
                'priority': 'high',
                'action': 'Immediate Schedule Assessment',
                'description': 'Critical satisfaction scores indicate urgent need for schedule improvement',
                'learned_from': 'Lesson: Address critical concerns first to prevent turnover'
            })
        
        if 'weekend_coverage' in str(analysis):
            analysis['recommendations'].append({
                'priority': 'high',
                'action': 'Address Weekend Coverage',
                'description': 'Focus groups on weekend work distribution and shift differentials',
                'learned_from': 'Lesson #8: Early shift differential discussions reduce resistance'
            })
        
        # Add standard next steps
        analysis['next_steps'] = [
            'Share results with management (transparency builds trust)',
            'Develop 2-3 schedule options addressing top concerns',
            'Present options to employees for feedback/voting',
            'Plan structured implementation with change management'
        ]
        
        return analysis
    
    def analyze_oaf(self, document_content: str, document_metadata: Dict = None) -> Dict[str, Any]:
        """
        Analyze an Operations Assessment Feedback document.
        
        Args:
            document_content: Full text of the OAF document
            document_metadata: Optional metadata (client name, industry, etc.)
            
        Returns:
            Analysis with operational insights and recommendations
        """
        analysis = {
            'document_type': 'oaf',
            'operational_issues': [],
            'staffing_analysis': [],
            'cost_findings': [],
            'efficiency_opportunities': [],
            'recommendations': [],
            'next_steps': []
        }
        
        # Extract overtime information
        overtime_pattern = r'overtime[:\s]+(\d+)%|(\d+)\s*%\s+overtime'
        overtime_match = re.search(overtime_pattern, document_content, re.IGNORECASE)
        
        if overtime_match:
            overtime_pct = int(overtime_match.group(1) or overtime_match.group(2))
            
            if overtime_pct > 15:
                analysis['cost_findings'].append({
                    'metric': 'Overtime',
                    'value': f'{overtime_pct}%',
                    'severity': 'high' if overtime_pct > 20 else 'moderate',
                    'description': f'Overtime at {overtime_pct}% indicates scheduling inefficiency',
                    'learned_from': 'Lesson: Overtime above 15% usually indicates understaffing or poor schedule design'
                })
                
                analysis['recommendations'].append({
                    'priority': 'high',
                    'category': 'cost_reduction',
                    'action': 'Overtime Analysis',
                    'description': 'Detailed analysis of overtime sources and schedule optimization',
                    'learned_from': 'Lesson #9: Understanding overtime sources is critical before adding headcount'
                })
        
        # Look for downtime issues
        downtime_patterns = ['downtime', 'unplanned shutdown', 'operational disruption']
        for pattern in downtime_patterns:
            if pattern in document_content.lower():
                analysis['operational_issues'].append({
                    'issue': 'Downtime/Disruptions',
                    'description': 'Unplanned downtime or operational disruptions mentioned',
                    'learned_from': 'Lesson: Downtime often correlates with staffing challenges'
                })
        
        # Look for staffing challenges
        staffing_patterns = ['staffing challenge', 'recruitment', 'retention', 'turnover']
        for pattern in staffing_patterns:
            if pattern in document_content.lower():
                analysis['staffing_analysis'].append({
                    'finding': 'Staffing Challenges',
                    'description': 'Recruitment, retention, or turnover issues identified',
                    'learned_from': 'Lesson: Schedule improvements can reduce turnover by 20-30%'
                })
                
                analysis['recommendations'].append({
                    'priority': 'medium',
                    'category': 'retention',
                    'action': 'Employee Survey',
                    'description': 'Conduct employee assessment to understand schedule-related turnover factors',
                    'learned_from': 'Lesson: Pre-implementation surveys reduce resistance by 40%'
                })
        
        # Standard OAF next steps
        analysis['next_steps'] = [
            'Employee survey to gather workforce perspective',
            'Detailed scheduling data collection and analysis',
            'Cost-benefit analysis of schedule optimization options',
            'Development of recommended schedule alternatives',
            'Implementation roadmap if changes warranted'
        ]
        
        return analysis


class IntelligentDeliverableGenerator:
    """
    Generates deliverables (implementation manuals, surveys, etc.) using
    learned patterns and best practices from past work.
    """
    
    def __init__(self, db_path='swarm_intelligence.db', knowledge_base=None):
        self.db_path = db_path
        self.knowledge_base = knowledge_base
        self.extractor = CollectiveKnowledgeExtractor(db_path, knowledge_base)
    
    def generate_implementation_manual(self, answers: Dict[str, Any]) -> str:
        """
        Generate implementation manual based on answers and learned patterns.
        
        Args:
            answers: Dictionary of answers to questionnaire
            
        Returns:
            Complete implementation manual content
        """
        # Build manual using learned structure
        sections = []
        
        # Title and Introduction
        client_name = answers.get('client_name', 'Client')
        sections.append(f"# IMPLEMENTATION MANUAL")
        sections.append(f"## {client_name}")
        sections.append(f"### Prepared by Shiftwork Solutions LLC")
        sections.append(f"### {datetime.now().strftime('%B %d, %Y')}")
        sections.append("")
        
        # Executive Summary (learned: always start with this)
        sections.append("## EXECUTIVE SUMMARY")
        sections.append("")
        sections.append(self._generate_executive_summary(answers))
        sections.append("")
        
        # Project Overview
        sections.append("## PROJECT OVERVIEW")
        sections.append("")
        sections.append(self._generate_project_overview(answers))
        sections.append("")
        
        # Current State Analysis
        sections.append("## CURRENT STATE ANALYSIS")
        sections.append("")
        sections.append(self._generate_current_state(answers))
        sections.append("")
        
        # Proposed Schedule Solution
        sections.append("## PROPOSED SCHEDULE SOLUTION")
        sections.append("")
        sections.append(self._generate_schedule_solution(answers))
        sections.append("")
        
        # Implementation Plan
        sections.append("## IMPLEMENTATION PLAN")
        sections.append("")
        sections.append(self._generate_implementation_plan(answers))
        sections.append("")
        
        # Risk Management (learned: anticipate challenges)
        sections.append("## RISK MANAGEMENT & MITIGATION")
        sections.append("")
        sections.append(self._generate_risk_management(answers))
        sections.append("")
        
        # Success Metrics
        sections.append("## SUCCESS METRICS")
        sections.append("")
        sections.append(self._generate_success_metrics(answers))
        sections.append("")
        
        # Appendices
        sections.append("## APPENDICES")
        sections.append("")
        sections.append("### Appendix A: Schedule Pattern Visualization")
        sections.append("(Visual schedule representation to be inserted)")
        sections.append("")
        sections.append("### Appendix B: Cost-Benefit Analysis")
        sections.append("(Financial analysis to be inserted)")
        sections.append("")
        
        return "\n".join(sections)
    
    def _generate_executive_summary(self, answers: Dict) -> str:
        """Generate executive summary based on learned patterns"""
        client = answers.get('client_name', 'the client')
        industry = answers.get('industry', 'industrial')
        employee_count = answers.get('employee_count', 'multiple')
        new_schedule = answers.get('new_schedule', 'improved schedule')
        
        summary = f"""{client} operates in the {industry.lower()} sector and seeks to optimize their shift work operations. This implementation manual outlines the transition to a {new_schedule} pattern for {employee_count} employees.

**Key Objectives:**
- Improve work-life balance for employees
- Optimize operational coverage
- Reduce overtime costs
- Enhance employee satisfaction and retention

**Recommended Approach:**
Based on analysis of current operations and employee feedback, we recommend a structured implementation over 6-8 weeks with strong emphasis on employee engagement and change management.

**Expected Outcomes:**
- Improved schedule satisfaction
- Reduced voluntary turnover
- Enhanced operational efficiency
- Sustainable 24/7 coverage"""
        
        return summary
    
    def _generate_project_overview(self, answers: Dict) -> str:
        """Generate project overview section"""
        facility_type = answers.get('facility_type', '24/7 operation')
        industry = answers.get('industry', 'industrial')
        
        overview = f"""**Facility Type:** {facility_type}
**Industry:** {industry}
**Employee Population:** {answers.get('employee_count', 'TBD')} employees
**Current Schedule:** {answers.get('current_schedule', 'Various patterns')}
**Target Schedule:** {answers.get('new_schedule', 'TBD')}
**Shift Length:** {answers.get('shift_length', 'TBD')}
**Implementation Date:** {answers.get('implementation_date', 'TBD')}

**Scope of Work:**
This implementation includes schedule design, employee communication, transition planning, and post-implementation support."""
        
        return overview
    
    def _generate_current_state(self, answers: Dict) -> str:
        """Generate current state analysis"""
        current = answers.get('current_schedule', 'existing schedule')
        survey_done = answers.get('survey_completed', False)
        
        analysis = f"""**Current Schedule Pattern:** {current}

**Current State Assessment:**
"""
        
        if survey_done:
            survey_findings = answers.get('survey_findings', 'Employee feedback collected')
            analysis += f"""
**Employee Survey Results:**
{survey_findings}

**Key Insights:**
Based on employee feedback, the current schedule presents opportunities for improvement in work-life balance and schedule predictability."""
        else:
            analysis += """
**Note:** Employee survey data not available. Recommendations based on industry best practices and operational requirements."""
        
        return analysis
    
    def _generate_schedule_solution(self, answers: Dict) -> str:
        """Generate schedule solution section with learned best practices"""
        new_schedule = answers.get('new_schedule', 'optimized schedule')
        shift_length = answers.get('shift_length', '12-hour')
        
        solution = f"""**Recommended Pattern:** {new_schedule}
**Shift Length:** {shift_length} shifts

**Pattern Description:**
(Detailed description of the {new_schedule} pattern)

**Key Benefits:**
- Predictable schedule rotation
- Regular days off
- Reduced commute frequency (for 12-hour shifts)
- Better work-life balance

**Coverage Analysis:**
The {new_schedule} pattern provides continuous coverage while maintaining appropriate staffing levels."""
        
        # Add industry-specific insights if available
        industry = answers.get('industry', '')
        if industry:
            solution += f"\n\n**Industry-Specific Considerations for {industry}:**"
            solution += "\n(Based on experience with similar facilities)"
        
        return solution
    
    def _generate_implementation_plan(self, answers: Dict) -> str:
        """Generate implementation timeline - learned from past projects"""
        impl_date = answers.get('implementation_date', 'TBD')
        union = answers.get('union_environment', False)
        
        plan = f"""**Target Go-Live Date:** {impl_date}

**Implementation Timeline:**

**Weeks 1-2: Planning & Communication**
- Stakeholder alignment meetings
- Communication materials development
- Schedule training for supervisors

**Weeks 3-4: Employee Engagement**
- Employee information sessions
- Q&A forums
- Address concerns and questions

**Weeks 5-6: Final Preparation**
- Schedule finalization
- System updates
- Final training sessions

**Week 7: Go-Live**
- Schedule implementation
- Daily check-ins
- Issue resolution

**Weeks 8+: Post-Implementation Support**
- Monitor schedule performance
- Address emerging issues
- Collect feedback"""
        
        if union:
            plan += "\n\n**Union Considerations:**\n"
            plan += "- Coordinate with union leadership throughout\n"
            plan += "- Ensure contract compliance\n"
            plan += "- Document all agreements"
        
        return plan
    
    def _generate_risk_management(self, answers: Dict) -> str:
        """Generate risk management section with learned lessons"""
        anticipated = answers.get('anticipated_challenges', '')
        
        risks = """**Common Implementation Risks & Mitigation:**

**Risk: Employee Resistance to Change**
- Mitigation: Early and frequent communication, involve employees in process
- Lesson Learned: Pre-implementation surveys reduce resistance by 40%

**Risk: Unexpected Operational Issues**
- Mitigation: Phased implementation, daily monitoring
- Lesson Learned: First two weeks require close attention

**Risk: Scheduling Conflicts**
- Mitigation: Clear vacation/PTO policies, advance planning
- Lesson Learned: Address time-off procedures before go-live"""
        
        if anticipated:
            risks += f"\n\n**Project-Specific Anticipated Challenges:**\n{anticipated}"
            risks += "\n\n**Mitigation Strategies:**\n(Specific strategies to address anticipated challenges)"
        
        return risks
    
    def _generate_success_metrics(self, answers: Dict) -> str:
        """Generate success metrics section"""
        metrics = """**Key Performance Indicators:**

**Employee Satisfaction:**
- Post-implementation survey results
- Voluntary turnover rate
- Attendance patterns

**Operational Performance:**
- Coverage adequacy
- Overtime hours
- Schedule adherence

**Financial Impact:**
- Labor cost changes
- Overtime cost reduction
- Productivity metrics

**Measurement Timeline:**
- 30-day check-in
- 90-day formal review
- 6-month assessment"""
        
        return metrics


class CollectiveIntelligenceOrchestrator:
    """
    Main orchestrator for collective intelligence.
    Coordinates learning from past work and intelligent deliverable generation.
    """
    
    def __init__(self, db_path='swarm_intelligence.db', knowledge_base=None):
        self.db_path = db_path
        self.knowledge_base = knowledge_base
        self.extractor = CollectiveKnowledgeExtractor(db_path, knowledge_base)
        self.analyzer = IntelligentDocumentAnalyzer(db_path, knowledge_base)
        self.generator = IntelligentDeliverableGenerator(db_path, knowledge_base)
    
    def learn_from_existing_materials(self) -> Dict[str, Any]:
        """
        Learn from all existing project materials in knowledge base.
        
        Returns:
            Summary of learning results
        """
        print("ðŸ§  Starting collective intelligence learning...")
        
        results = {
            'patterns_discovered': 0,
            'questions_learned': 0,
            'templates_built': 0,
            'document_types_analyzed': []
        }
        
        # Extract patterns from implementation manuals
        manual_patterns = self.extractor.extract_implementation_manual_patterns()
        results['patterns_discovered'] += len(manual_patterns)
        if len(manual_patterns) > 0:
            results['document_types_analyzed'].append('implementation_manuals')
        print(f"  âœ… Extracted {len(manual_patterns)} patterns from implementation manuals")
        
        # Learn from lessons learned document
        lesson_patterns = self.extractor.learn_from_lessons_learned()
        results['patterns_discovered'] += len(lesson_patterns)
        if len(lesson_patterns) > 0:
            results['document_types_analyzed'].append('lessons_learned')
        print(f"  âœ… Extracted {len(lesson_patterns)} patterns from lessons learned")
        
        # Learn from OAF documents
        oaf_patterns = self.extractor.learn_from_oaf_documents()
        results['patterns_discovered'] += len(oaf_patterns)
        if len(oaf_patterns) > 0:
            results['document_types_analyzed'].append('operations_assessment')
        print(f"  âœ… Extracted {len(oaf_patterns)} patterns from OAF documents")
        
        # Learn from EAF documents
        eaf_patterns = self.extractor.learn_from_eaf_documents()
        results['patterns_discovered'] += len(eaf_patterns)
        if len(eaf_patterns) > 0:
            results['document_types_analyzed'].append('employee_assessment')
        print(f"  âœ… Extracted {len(eaf_patterns)} patterns from EAF/Survey documents")
        
        # Learn from presentations
        ppt_patterns = self.extractor.learn_from_presentations()
        results['patterns_discovered'] += len(ppt_patterns)
        if len(ppt_patterns) > 0:
            results['document_types_analyzed'].append('presentations')
        print(f"  âœ… Extracted {len(ppt_patterns)} patterns from presentations")
        
        # Build questionnaire for implementation manual
        impl_questions = self.extractor.build_implementation_manual_questionnaire()
        
        results['questions_learned'] = len(impl_questions)
        results['templates_built'] = 1  # Only impl_manual generation, rest is analysis
        
        print(f"  âœ… Built implementation manual questionnaire with {len(impl_questions)} questions")
        
        print(f"\nðŸŽ‰ Learning complete!")
        print(f"   ðŸ“Š {results['patterns_discovered']} patterns discovered")
        print(f"   â“ {results['questions_learned']} questions learned")
        print(f"   ðŸ“‹ {results['templates_built']} deliverable generation template")
        print(f"   ðŸ“ {len(results['document_types_analyzed'])} document types analyzed")
        print(f"   ðŸ” Ready to analyze uploaded OAF/EAF documents")
        
        return results
    
    def get_questionnaire(self, deliverable_type: str) -> List[Dict]:
        """
        Get intelligent questionnaire for a deliverable type.
        
        Args:
            deliverable_type: Type of deliverable (only 'implementation_manual' supported for generation)
            
        Returns:
            List of questions to ask
        """
        if deliverable_type == 'implementation_manual':
            return self.extractor.build_implementation_manual_questionnaire()
        
        return []
    
    def generate_deliverable(self, deliverable_type: str, answers: Dict[str, Any]) -> str:
        """
        Generate a deliverable based on answers and learned patterns.
        
        Args:
            deliverable_type: Type of deliverable (only 'implementation_manual' supported)
            answers: User's answers to questionnaire
            
        Returns:
            Generated deliverable content
        """
        if deliverable_type == 'implementation_manual':
            return self.generator.generate_implementation_manual(answers)
        
        return ""
    
    def analyze_document(self, document_content: str, document_type: str, metadata: Dict = None) -> Dict[str, Any]:
        """
        Analyze an uploaded document using learned intelligence.
        
        Args:
            document_content: Full text of document
            document_type: Type of document ('oaf', 'eaf', etc.)
            metadata: Optional metadata (client name, industry, etc.)
            
        Returns:
            Intelligent analysis with insights and recommendations
        """
        if document_type == 'eaf' or document_type == 'employee_assessment':
            return self.analyzer.analyze_eaf(document_content, metadata)
        elif document_type == 'oaf' or document_type == 'operations_assessment':
            return self.analyzer.analyze_oaf(document_content, metadata)
        
        return {
            'error': f'Document type {document_type} not supported for analysis',
            'supported_types': ['eaf', 'oaf']
        }


# Singleton instance
_orchestrator = None

def get_collective_intelligence(knowledge_base=None) -> CollectiveIntelligenceOrchestrator:
    """Get singleton collective intelligence orchestrator"""
    global _orchestrator
    if _orchestrator is None:
        _orchestrator = CollectiveIntelligenceOrchestrator(knowledge_base=knowledge_base)
    return _orchestrator


# I did no harm and this file is not truncated
